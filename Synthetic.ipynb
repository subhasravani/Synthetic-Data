{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Synthetic Data Generation for Fraud Detection in Financial Transactions\n",
        "This project will guide you through creating a synthetic dataset for fraud detection, training a machine learning model, and evaluating its performance."
      ],
      "metadata": {
        "id": "d7lctcORqL7M"
      }
    },
    {
      "source": [
        "#1. Data Generation\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define number of samples\n",
        "n_samples = 10000\n",
        "\n",
        "# Simulate transaction features\n",
        "transaction_amount = np.random.exponential(scale=100, size=n_samples)\n",
        "merchant_category = np.random.randint(1, 10, size=n_samples)\n",
        "time_of_day = np.random.randint(0, 24, size=n_samples)\n",
        "location = np.random.rand(n_samples) * 100\n",
        "is_weekend = np.random.randint(0, 2, size=n_samples)\n",
        "previous_transactions = np.random.randint(0, 20, size=n_samples)\n",
        "average_transaction_amount = np.random.exponential(scale=50, size=n_samples)\n",
        "\n",
        "# Simulate fraud labels (0 for non-fraud, 1 for fraud)\n",
        "fraud_probability = 0.05\n",
        "is_fraud = np.random.choice([0, 1], size=n_samples, p=[1 - fraud_probability, fraud_probability])\n",
        "\n",
        "# Introduce correlations to make the data more realistic\n",
        "# Example: Larger transaction amounts are more likely to be fraudulent\n",
        "fraud_indices = np.where(is_fraud == 1)\n",
        "transaction_amount[fraud_indices] = np.random.exponential(scale=300, size=len(fraud_indices[0]))\n",
        "\n",
        "# Create a Pandas DataFrame\n",
        "data = {\n",
        "    'transaction_amount': transaction_amount,\n",
        "    'merchant_category': merchant_category,\n",
        "    'time_of_day': time_of_day,\n",
        "    'location': location,\n",
        "    'is_weekend': is_weekend,\n",
        "    'previous_transactions': previous_transactions,\n",
        "    'average_transaction_amount': average_transaction_amount,\n",
        "    'is_fraud': is_fraud\n",
        "}\n",
        "df = pd.DataFrame(data)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "0JxCjKOmqIse"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "source": [
        "#2. Data Preprocessing\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop('is_fraud', axis=1)\n",
        "y = df['is_fraud']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "nTxLIQ7YqUjS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "source": [
        "#3. Address Class Imbalance (SMOTE)\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Apply SMOTE to oversample the minority class (fraudulent transactions)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "E93SFP1_qa3E"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "source": [
        "#4. Model Training and Evaluation\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# Initialize and train a RandomForestClassifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7E0YtyqqfCD",
        "outputId": "135a2e83-144c-4b5a-a49d-feb7b78bdd88"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.95      1897\n",
            "           1       0.22      0.35      0.27       103\n",
            "\n",
            "    accuracy                           0.90      2000\n",
            "   macro avg       0.59      0.64      0.61      2000\n",
            "weighted avg       0.93      0.90      0.91      2000\n",
            "\n",
            "ROC AUC Score: 0.6955489249760736\n"
          ]
        }
      ]
    },
    {
      "source": [
        "     import xgboost as xgb\n",
        "\n",
        "     # Initialize and train an XGBoost classifier\n",
        "     xgb_model = xgb.XGBClassifier(random_state=42)\n",
        "     xgb_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "     # Make predictions on the test set\n",
        "     y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "     # Evaluate the XGBoost model\n",
        "     print(classification_report(y_test, y_pred_xgb))\n",
        "     print(\"XGBoost ROC AUC Score:\", roc_auc_score(y_test, xgb_model.predict_proba(X_test)[:, 1]))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4zGNBU6q6jY",
        "outputId": "92d650fc-de60-496a-a9fa-a54bb7628bc2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.90      0.93      1897\n",
            "           1       0.16      0.38      0.23       103\n",
            "\n",
            "    accuracy                           0.87      2000\n",
            "   macro avg       0.56      0.64      0.58      2000\n",
            "weighted avg       0.92      0.87      0.89      2000\n",
            "\n",
            "XGBoost ROC AUC Score: 0.6662179936639865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Feature Engineering:\n",
        "\n",
        "import pandas as pd\n",
        "# Feature Engineering\n",
        "df['transaction_hour'] = df['time_of_day'].apply(lambda x: x // 4) #Group time into 6 hour buckets\n",
        "df['transaction_amount_binned'] = pd.cut(df['transaction_amount'], bins=10, labels=False)\n",
        "df['high_value_transaction'] = (df['transaction_amount'] > 200).astype(int) # High value transaction\n",
        "df['transaction_ratio'] = df['transaction_amount'] / df['average_transaction_amount'] # ratio\n",
        "df['recent_transactions_flag'] = (df['previous_transactions'] > 5).astype(int)\n",
        "#Interaction Features\n",
        "df['merchant_hour_interaction'] = df['merchant_category'] * df['transaction_hour']\n",
        "\n",
        "# Drop original time of day\n",
        "df = df.drop('time_of_day', axis=1)\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop('is_fraud', axis=1)\n",
        "y = df['is_fraud']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE to oversample the minority class (fraudulent transactions)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "ve4oe8a5rJ-m"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression, Support Vector,neural networks\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "# 4. Model Building and Evaluation (Logistic Regression)\n",
        "logreg_model = LogisticRegression(random_state=42)\n",
        "logreg_model.fit(X_resampled, y_resampled)\n",
        "y_pred_logreg = logreg_model.predict(X_test)\n",
        "\n",
        "print(\"Logistic Regression:\")\n",
        "print(classification_report(y_test, y_pred_logreg))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test, logreg_model.predict_proba(X_test)[:, 1]))\n",
        "\n",
        "\n",
        "# 4. Model Building and Evaluation (Support Vector Machine)\n",
        "svm_model = SVC(random_state=42, probability=True) # probability=True for ROC AUC\n",
        "svm_model.fit(X_resampled, y_resampled)\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "print(\"\\nSupport Vector Machine:\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test, svm_model.predict_proba(X_test)[:, 1]))\n",
        "\n",
        "\n",
        "# 4. Model Building and Evaluation (Neural Network)\n",
        "nn_model = MLPClassifier(random_state=42, max_iter=500) # Increased max_iter for convergence\n",
        "nn_model.fit(X_resampled, y_resampled)\n",
        "y_pred_nn = nn_model.predict(X_test)\n",
        "\n",
        "print(\"\\nNeural Network:\")\n",
        "print(classification_report(y_test, y_pred_nn))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test, nn_model.predict_proba(X_test)[:, 1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJcGoGFyro6F",
        "outputId": "c3754d39-3f88-4b92-f459-3f200470d2aa"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.64      0.69      1928\n",
            "           1       0.68      0.78      0.72      1881\n",
            "\n",
            "    accuracy                           0.70      3809\n",
            "   macro avg       0.71      0.71      0.70      3809\n",
            "weighted avg       0.71      0.70      0.70      3809\n",
            "\n",
            "ROC AUC Score: 0.8027771711436268\n",
            "\n",
            "Support Vector Machine:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.73      0.69      1928\n",
            "           1       0.69      0.61      0.65      1881\n",
            "\n",
            "    accuracy                           0.67      3809\n",
            "   macro avg       0.67      0.67      0.67      3809\n",
            "weighted avg       0.67      0.67      0.67      3809\n",
            "\n",
            "ROC AUC Score: 0.7271013531250483\n",
            "\n",
            "Neural Network:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.91      0.81      1928\n",
            "           1       0.88      0.64      0.74      1881\n",
            "\n",
            "    accuracy                           0.78      3809\n",
            "   macro avg       0.80      0.78      0.77      3809\n",
            "weighted avg       0.80      0.78      0.77      3809\n",
            "\n",
            "ROC AUC Score: 0.871168829593158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensemble Methods\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Assuming X_resampled, y_resampled, X_test, y_test are defined from the previous code\n",
        "\n",
        "# Create individual models\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "xgb_model = xgb.XGBClassifier(random_state=42)\n",
        "logreg_model = LogisticRegression(random_state=42)\n",
        "\n",
        "# Create the voting classifier\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('rf', rf_model), ('xgb', xgb_model), ('lr', logreg_model)],\n",
        "    voting='soft'  # Use 'soft' voting for better performance with probabilities\n",
        ")\n",
        "\n",
        "# Train the voting classifier\n",
        "voting_clf.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_voting = voting_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the voting classifier\n",
        "print(\"\\nVoting Classifier:\")\n",
        "print(classification_report(y_test, y_pred_voting))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test, voting_clf.predict_proba(X_test)[:, 1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKbL_W0or1Br",
        "outputId": "c8fa43c9-e097-4a2f-f0b1-3289aa7c3f79"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Voting Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1928\n",
            "           1       0.98      0.96      0.97      1881\n",
            "\n",
            "    accuracy                           0.97      3809\n",
            "   macro avg       0.97      0.97      0.97      3809\n",
            "weighted avg       0.97      0.97      0.97      3809\n",
            "\n",
            "ROC AUC Score: 0.997275661176076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pickle\n",
        "# Save the trained model\n",
        "filename = 'voting_classifier_model.pkl'\n",
        "pickle.dump(voting_clf, open(filename, 'wb'))\n"
      ],
      "metadata": {
        "id": "sRX3HLSHtTtO"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt:  deploy ensembled model with flask\n",
        "\n",
        "!pip install flask\n",
        "!pip install gunicorn\n",
        "\n",
        "import pickle\n",
        "from flask import Flask, request, jsonify\n",
        "\n",
        "# Load the trained model\n",
        "filename = 'voting_classifier_model.pkl'\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        # Assuming the input data is a list of features\n",
        "        features = data['features']  # Access features using the key 'features'\n",
        "\n",
        "        # Make a prediction\n",
        "        prediction = loaded_model.predict([features])[0]\n",
        "\n",
        "        # Prepare the response\n",
        "        response = {'prediction': int(prediction)} # Convert to integer for clarity\n",
        "        return jsonify(response)\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 500  # Return an error response\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True, host='0.0.0.0', port=int(5000)) # Specify port explicitly\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf60JS9JuA2x",
        "outputId": "6e57eea4-6bfe-4d1b-a77d-5a0a99a8c645"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (2.3.2)\n",
            "Requirement already satisfied: Werkzeug>=2.3.3 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Collecting gunicorn\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gunicorn) (24.2)\n",
            "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gunicorn\n",
            "Successfully installed gunicorn-23.0.0\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    }
  ]
}